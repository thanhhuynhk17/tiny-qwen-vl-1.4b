{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# Add the project root directory to the Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(project_root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rope 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.utils.rope2d import get_rope_2d_angles, apply_2d_rope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 768])\n",
      "Q:\n",
      " tensor([[[ 1.9269,  1.4873,  0.9007,  ..., -1.6034, -0.4298,  0.5762],\n",
      "         [ 1.9269,  1.4873,  0.9007,  ..., -1.6034, -0.4298,  0.5762],\n",
      "         [-0.8497, -0.6987, -0.2052,  ..., -0.0298,  1.2715,  1.0849],\n",
      "         [ 1.9269,  1.4873,  0.9007,  ..., -1.6034, -0.4298,  0.5762]]])\n",
      "Q_r:\n",
      " tensor([[[ 1.9269,  1.4873,  0.9007,  ..., -1.6034, -0.4298,  0.5762],\n",
      "         [-0.2104,  2.4250,  2.2381,  ..., -1.6034, -0.4298,  0.5762],\n",
      "         [-0.8497, -0.6987, -0.2052,  ..., -0.0298,  1.2714,  1.0850],\n",
      "         [-0.2104,  2.4250,  2.2381,  ..., -1.6034, -0.4299,  0.5761]]])\n"
     ]
    }
   ],
   "source": [
    "batch_size, seq_len, embed_dim = 1, 4, 768\n",
    "\n",
    "torch.manual_seed(42)\n",
    "Q = torch.randn((batch_size, seq_len, embed_dim))\n",
    "Q[0][1] = Q[0][0]\n",
    "Q[0][3] = Q[0][0]\n",
    "# Q[1][3] = Q[1][0]\n",
    "print(Q.shape)\n",
    "print(\"Q:\\n\", Q)\n",
    "cos_theta, sin_theta = get_rope_2d_angles(embed_dim, int(seq_len**0.5))\n",
    "\n",
    "Q_r = apply_2d_rope(Q, cos_theta, sin_theta)\n",
    "print(\"Q_r:\\n\", Q_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute L2 norm before and after rotation\n",
    "norm_before = torch.norm(Q, dim=-1)     # [bsz, seq_len]\n",
    "norm_after  = torch.norm(Q_r, dim=-1)   # [bsz, seq_len]\n",
    "# Check equality\n",
    "torch.allclose(norm_before, norm_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[    0.15,     0.04,     0.00,     0.11],\n",
      "         [    0.08,     0.09,     0.00,     0.01],\n",
      "         [    0.00,     0.00,     0.00,     0.00],\n",
      "         [    0.13,     0.01,     0.00,     0.12]]])\n"
     ]
    }
   ],
   "source": [
    "# Check attention score (self attention) before & after rotation\n",
    "batch_size, seq_len, embed_dim= Q.shape\n",
    "\n",
    "# attention score\n",
    "score_before = torch.matmul(Q, Q.transpose(-1, -2)) / (embed_dim**0.5)\n",
    "score_before = torch.softmax(score_before, dim=-1)\n",
    "\n",
    "score_after  = torch.matmul(Q_r, Q_r.transpose(-1, -2)) / (embed_dim**0.5)\n",
    "score_after  = torch.softmax(score_after, dim=-1)\n",
    "\n",
    "\n",
    "diff = (score_before - score_after).abs()\n",
    "# round to 2 digits\n",
    "torch.set_printoptions(precision=2, sci_mode=False)\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absolute Position Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.abs_pos_embed import get_2d_sincos_pos_embed\n",
    "\n",
    "abs_pos_embed = get_2d_sincos_pos_embed(embed_dim, int(seq_len**0.5))\n",
    "abs_pos_embed = torch.from_numpy(abs_pos_embed)\n",
    "Q_abs_r = Q+abs_pos_embed.unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute L2 norm before and after rotation\n",
    "norm_before = torch.norm(Q, dim=-1)     # [bsz, seq_len]\n",
    "norm_after  = torch.norm(Q_abs_r, dim=-1)   # [bsz, seq_len]\n",
    "# Check equality\n",
    "torch.allclose(norm_before, norm_after, atol=1e0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.02, 0.08, 0.19, 0.09],\n",
       "          [0.08, 0.04, 0.19, 0.07],\n",
       "          [0.17, 0.17, 0.52, 0.17],\n",
       "          [0.10, 0.06, 0.19, 0.03]]]),\n",
       " tensor(0.14))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check attention score (self attention) before & after rotation\n",
    "batch_size, seq_len, embed_dim= Q.shape\n",
    "\n",
    "score_after_abs  = torch.matmul(Q_abs_r, Q_abs_r.transpose(-1, -2)) / (embed_dim**0.5)\n",
    "score_after_abs  = torch.softmax(score_after, dim=-1)\n",
    "\n",
    "diff_abs = (score_before - score_after_abs).abs()\n",
    "# round to 2 digits\n",
    "torch.set_printoptions(precision=2, sci_mode=False)\n",
    "diff_abs, diff_abs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[    0.33,     0.33,     0.00,     0.33],\n",
       "         [    0.33,     0.33,     0.00,     0.33],\n",
       "         [    0.00,     0.00,     1.00,     0.00],\n",
       "         [    0.33,     0.33,     0.00,     0.33]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# self attention with Q shape [1, 4, 768]\n",
    "# Q[0][1] = Q[0][0]\n",
    "# Q[0][3] = Q[0][0]\n",
    "score_before # attention score before apply position embeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.05)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[    0.48,     0.29,     0.00,     0.22],\n",
       "         [    0.26,     0.42,     0.00,     0.32],\n",
       "         [    0.00,     0.00,     1.00,     0.00],\n",
       "         [    0.21,     0.34,     0.00,     0.45]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print((score_before - score_after).abs().mean())\n",
    "score_after # rope 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.31, 0.26, 0.19, 0.24],\n",
       "         [0.25, 0.29, 0.19, 0.26],\n",
       "         [0.17, 0.17, 0.48, 0.17],\n",
       "         [0.24, 0.27, 0.19, 0.30]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print((score_before - score_after_abs).abs().mean())\n",
    "score_after_abs # abs position encoding 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinyqwenvl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
